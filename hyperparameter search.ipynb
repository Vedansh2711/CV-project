{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkMyK2RGwzMT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import keras_tuner as kt\n",
        "# Set seeds\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3GHDZOKoXmV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "meta = pd.read_csv('Train_Test_Split.csv')\n",
        "meta = meta[meta['label'].isin(['AD', 'Healthy'])]\n",
        "\n",
        "train_meta = meta[meta['split'] == 'train']\n",
        "test_meta = meta[meta['split'] == 'test']\n",
        "\n",
        "def load_and_segment(subject_id, data_dir='Data_sampled_128HZ', segment_len=1024):\n",
        "    file_path = os.path.join(data_dir, f\"{subject_id}_data.npy\")\n",
        "    data = np.load(file_path)\n",
        "    _, time_steps = data.shape\n",
        "    num_segments = time_steps // segment_len\n",
        "    if num_segments == 0:\n",
        "        return np.empty((0, 19, segment_len))\n",
        "    data = data[:, :num_segments * segment_len]\n",
        "    segments = data.reshape(19, num_segments, segment_len).transpose(1, 0, 2)\n",
        "    return segments\n",
        "\n",
        "def process_data(meta_df, data_dir='Data_sampled_128HZ'):\n",
        "    X = []\n",
        "    y = []\n",
        "    label_map = {'AD': 1, 'Healthy': 0}\n",
        "    for _, row in meta_df.iterrows():\n",
        "        segments = load_and_segment(row['subject_id'], data_dir)\n",
        "        if segments.shape[0] == 0:\n",
        "            continue\n",
        "        X.append(segments)\n",
        "        label = label_map[row['label']]\n",
        "        one_hot = np.eye(2)[label]\n",
        "        y.extend([one_hot] * segments.shape[0])\n",
        "    X = np.concatenate(X, axis=0)\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "X_train, y_train = process_data(train_meta)\n",
        "X_test, y_test = process_data(test_meta)\n",
        "X_train = (X_train * 1e6) - np.mean(X_train * 1e6, axis=2, keepdims=True)\n",
        "X_test = (X_test * 1e6) - np.mean(X_test * 1e6, axis=2, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2tG3wLIpR8N"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model, Model\n",
        "\n",
        "def load_and_trim_model(path):\n",
        "    model = load_model(path)\n",
        "    model.pop() \n",
        "    model.trainable = False  # freeze\n",
        "    return model\n",
        "bilstm_model = load_and_trim_model('Models\\Final_Bilstm_model.keras')\n",
        "cnn_time_model = load_and_trim_model('Models\\Final_CNNSpatial_model.keras')\n",
        "cnn_freq_model = load_and_trim_model('Models\\Final_CNNSpectral_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONSpmFBt41V-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout, MultiHeadAttention, GlobalAveragePooling1D, Concatenate, Lambda, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_fusion_model_with_transformer(bilstm_model, cnn_time_model, cnn_freq_model, common_dim=128, num_heads=4, ff_dim=256, dropout_rate=0.3):\n",
        "    bilstm_input = Input(shape=bilstm_model.output_shape[1:])\n",
        "    cnn_time_input = Input(shape=cnn_time_model.output_shape[1:])\n",
        "    cnn_freq_input = Input(shape=cnn_freq_model.output_shape[1:])\n",
        "\n",
        "    bilstm_proj = Dense(common_dim)(bilstm_input)\n",
        "    cnn_time_proj = Dense(common_dim)(cnn_time_input)\n",
        "    cnn_freq_proj = Dense(common_dim)(cnn_freq_input)\n",
        "\n",
        "    x = Lambda(lambda t: tf.stack(t, axis=1))([bilstm_proj, cnn_time_proj, cnn_freq_proj])\n",
        "\n",
        "    for _ in range(2):\n",
        "        attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=common_dim)(x, x)\n",
        "        x = LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
        "\n",
        "        ffn_output = Dense(ff_dim, activation='relu')(x)\n",
        "        ffn_output = Dense(common_dim)(ffn_output)\n",
        "        x = LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
        "\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    out = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=[bilstm_input, cnn_time_input, cnn_freq_input], outputs=out)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo_BCNvc45gf"
      },
      "outputs": [],
      "source": [
        "fusion_model = build_fusion_model_with_transformer(\n",
        "    bilstm_model, cnn_time_model, cnn_freq_model,\n",
        "    common_dim=128, num_heads=4, ff_dim=256, dropout_rate=0.3\n",
        ")\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-3) \n",
        "\n",
        "fusion_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy','AUC'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6GUHXMQ47sS"
      },
      "outputs": [],
      "source": [
        "#BiLSTM Inputs\n",
        "top_channels = [14, 2, 0, 18, 4]\n",
        "X_train_selected = X_train[:, top_channels, :].transpose(0, 2, 1)  # (samples, 1024, 5)\n",
        "X_test_selected = X_test[:, top_channels, :].transpose(0, 2, 1)    # (samples, 1024, 5)\n",
        "X_bilstm_input = X_train_selected\n",
        "# CNNSPatial Inputs\n",
        "X_train_cnn = X_train[..., np.newaxis]  # shape: (N, 19, 1024, 1)\n",
        "X_test_cnn = X_test[..., np.newaxis]\n",
        "X_cnn_time_input = X_train_cnn\n",
        "#CNNSpectral Inputs\n",
        "from scipy.signal import welch\n",
        "\n",
        "def compute_spectral_features(X, fs=128, nperseg=256):\n",
        "    num_segments, num_channels, num_samples = X.shape\n",
        "    psd_all = []\n",
        "\n",
        "    for seg in X:\n",
        "        seg_psd = []\n",
        "        for ch in seg:\n",
        "            freqs, psd = welch(ch, fs=fs, nperseg=nperseg)\n",
        "            seg_psd.append(psd)\n",
        "        psd_all.append(seg_psd)\n",
        "\n",
        "    psd_all = np.array(psd_all)  \n",
        "    psd_all = np.log1p(psd_all)  \n",
        "    return psd_all, freqs\n",
        "\n",
        "X_train_spec, freqs = compute_spectral_features(X_train)\n",
        "X_test_spec, _ = compute_spectral_features(X_test)\n",
        "\n",
        "X_train_spec = X_train_spec[..., np.newaxis]  # shape: (N, 19, freq_bins, 1)\n",
        "X_test_spec = X_test_spec[..., np.newaxis]\n",
        "\n",
        "X_cnn_freq_input = X_train_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTS1bHnU5Cuu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPjqVTCM5Ekk",
        "outputId": "406d3e35-64f9-485c-d4f1-49a21665a467"
      },
      "outputs": [],
      "source": [
        "X_bilstm_feat = bilstm_model.predict(X_bilstm_input)\n",
        "X_cnn_time_feat = cnn_time_model.predict(X_cnn_time_input)\n",
        "X_cnn_freq_feat = cnn_freq_model.predict(X_cnn_freq_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O3cUFs75Gj0",
        "outputId": "c51f7638-7067-4064-9584-1b634eebfb5c"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout, MultiHeadAttention, GlobalAveragePooling1D, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "\n",
        "# This function defines the searchable model. \n",
        "# Note the Input shapes match the features you already extracted.\n",
        "def build_hypermodel(hp):\n",
        "    # --- Define hyperparameters for the second, focused search ---\n",
        "    \n",
        "    # Best was 256 (the max). Let's explore higher values.\n",
        "    hp_common_dim = hp.Int('common_dim', min_value=192, max_value=512, step=64)\n",
        "    \n",
        "    # Best was 8 (the max). Let's explore around and slightly above it.\n",
        "    hp_num_heads = hp.Choice('num_heads', values=[6, 8, 10, 12])\n",
        "    \n",
        "    # Best was 256 (in the middle). Let's zoom in with smaller steps.\n",
        "    hp_ff_dim = hp.Int('ff_dim', min_value=192, max_value=384, step=64)\n",
        "    \n",
        "    # Best was 0.2 (low end). Let's search a tighter range around it.\n",
        "    hp_dropout = hp.Float('dropout_rate', min_value=0.1, max_value=0.3, step=0.05)\n",
        "    \n",
        "    # Best was 0.00068. Let's center the log-scale search around that magnitude.\n",
        "    hp_lr = hp.Float('learning_rate', min_value=1e-4, max_value=9e-4, sampling='log')\n",
        "    \n",
        "    # Best was 2 (in the middle). Let's see if 2, 3, or 4 is optimal.\n",
        "    hp_num_blocks = hp.Int('num_transformer_blocks', min_value=2, max_value=4, step=1)\n",
        "\n",
        "    # --- Your existing model-building code ---\n",
        "    # (No changes needed to the section below)\n",
        "    \n",
        "    bilstm_input = Input(shape=X_bilstm_feat.shape[1:])\n",
        "    cnn_time_input = Input(shape=X_cnn_time_feat.shape[1:])\n",
        "    cnn_freq_input = Input(shape=X_cnn_freq_feat.shape[1:])\n",
        "\n",
        "    bilstm_proj = Dense(hp_common_dim)(bilstm_input)\n",
        "    cnn_time_proj = Dense(hp_common_dim)(cnn_time_input)\n",
        "    cnn_freq_proj = Dense(hp_common_dim)(cnn_freq_input)\n",
        "\n",
        "    x = Lambda(lambda t: tf.stack(t, axis=1))([bilstm_proj, cnn_time_proj, cnn_freq_proj])\n",
        "\n",
        "    for _ in range(hp_num_blocks):\n",
        "        attn_output = MultiHeadAttention(num_heads=hp_num_heads, key_dim=hp_common_dim)(x, x)\n",
        "        x = LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
        "\n",
        "        ffn_output = Dense(hp_ff_dim, activation='relu')(x)\n",
        "        ffn_output = Dense(hp_common_dim)(ffn_output)\n",
        "        x = LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
        "\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dropout(hp_dropout)(x)\n",
        "    out = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=[bilstm_input, cnn_time_input, cnn_freq_input], outputs=out)\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=hp_lr),\n",
        "        loss='categorical_crossentropy', \n",
        "        metrics=['accuracy', 'AUC']\n",
        "    )\n",
        "    return model\n",
        "# --- This section replaces your original .fit() call ---\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Define your callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "]\n",
        "\n",
        "# --- New Step: Create a stable validation set ---\n",
        "# We will split your pre-computed features and labels one time.\n",
        "\n",
        "# Get the total number of samples\n",
        "num_samples = X_bilstm_feat.shape[0]\n",
        "# Create an array of indices [0, 1, 2, ..., num_samples-1]\n",
        "indices = np.arange(num_samples)\n",
        "\n",
        "# Split the *indices* into training and validation sets\n",
        "# We use random_state=42 to ensure this split is the same every time you run it\n",
        "train_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the training sets using the train_indices\n",
        "X_bilstm_train = X_bilstm_feat[train_indices]\n",
        "X_cnn_time_train = X_cnn_time_feat[train_indices]\n",
        "X_cnn_freq_train = X_cnn_freq_feat[train_indices]\n",
        "y_train_main = y_train[train_indices]\n",
        "\n",
        "# Create the validation sets using the val_indices\n",
        "X_bilstm_val = X_bilstm_feat[val_indices]\n",
        "X_cnn_time_val = X_cnn_time_feat[val_indices]\n",
        "X_cnn_freq_val = X_cnn_freq_feat[val_indices]\n",
        "y_val_main = y_train[val_indices]\n",
        "\n",
        "\n",
        "# --- Now, run the tuner using this stable validation set ---\n",
        "\n",
        "# Initialize the tuner (using your refined build_hypermodel function)\n",
        "tuner = kt.RandomSearch(\n",
        "    build_hypermodel, \n",
        "    objective=kt.Objective(\"val_AUC\", direction=\"max\"),\n",
        "    max_trials=20, \n",
        "    executions_per_trial=1,\n",
        "    directory='my_tuner_dir_run2', # Use a new directory for this new run\n",
        "    project_name='eeg_fusion_stable'\n",
        ")\n",
        "\n",
        "# Run the hyperparameter search\n",
        "print(\"--- Starting Stable Hyperparameter Search ---\")\n",
        "tuner.search(\n",
        "    # Use the new training sets\n",
        "    [X_bilstm_train, X_cnn_time_train, X_cnn_freq_train],\n",
        "    y_train_main,\n",
        "    \n",
        "    # Use the new validation_data argument instead of validation_split\n",
        "    validation_data=(\n",
        "        [X_bilstm_val, X_cnn_time_val, X_cnn_freq_val],\n",
        "        y_val_main\n",
        "    ),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "print(\"--- Hyperparameter Search Finished ---\")\n",
        "\n",
        "\n",
        "# --- Get results and train the final model ---\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"\\nOptimal hyperparameters found:\")\n",
        "for hp, value in best_hps.values.items():\n",
        "    print(f\"- {hp}: {value}\")\n",
        "\n",
        "# Build the final model with the best hyperparameters\n",
        "final_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the final model on the *entire training set*\n",
        "# (X_bilstm_feat, X_cnn_time_feat, etc. contain 100% of the training data)\n",
        "history = final_model.fit(\n",
        "    [X_bilstm_feat, X_cnn_time_feat, X_cnn_freq_feat],\n",
        "    y_train,\n",
        "    epochs=100, # Train for longer\n",
        "    batch_size=32,\n",
        "    # We use the same stable validation set again for monitoring\n",
        "    validation_data=(\n",
        "        [X_bilstm_val, X_cnn_time_val, X_cnn_freq_val],\n",
        "        y_val_main\n",
        "    ),\n",
        "    callbacks=callbacks \n",
        ")\n",
        "\n",
        "# --- Finally, evaluate the best model on the unseen test data ---\n",
        "print(\"\\n--- Evaluating best model on the test set ---\")\n",
        "X_test_bilstm_feat = bilstm_model.predict(X_test_selected)\n",
        "X_test_cnn_time_feat = cnn_time_model.predict(X_test_cnn)\n",
        "X_test_cnn_freq_feat = cnn_freq_model.predict(X_test_spec)\n",
        "\n",
        "test_loss, test_acc, test_auc = final_model.evaluate(\n",
        "    [X_test_bilstm_feat, X_test_cnn_time_feat, X_test_cnn_freq_feat], \n",
        "    y_test\n",
        ")\n",
        "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}, Final Test AUC: {test_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlFGFBQw6WF_",
        "outputId": "1d879cd4-619a-4dea-8136-e4ddeb2a935e"
      },
      "outputs": [],
      "source": [
        "X_bilstm_test_feat = bilstm_model.predict(X_test_selected)\n",
        "X_cnn_time_test_feat = cnn_time_model.predict(X_test_cnn)\n",
        "X_cnn_freq_test_feat = cnn_freq_model.predict(X_test_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdheR3AC5IbK",
        "outputId": "419763aa-a374-4339-dc34-a50eed663a6f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
        "\n",
        "y_pred = fusion_model.predict([X_bilstm_test_feat, X_cnn_time_test_feat, X_cnn_freq_test_feat])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"ROC AUC:\", roc_auc_score(y_true, y_pred[:, 1]))\n",
        "print(\"Average Precision:\", average_precision_score(y_true, y_pred[:, 1]))\n",
        "print(classification_report(y_true, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_folder = \"Models\"\n",
        "os.makedirs(output_folder,exist_ok=True)\n",
        "model_path = os.path.join(output_folder,\"Final_End_to_End_model.keras\")\n",
        "model.save(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_JK33VV5Vgf"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "def patient_level_ensemble_2(fusion_model, bilstm_model, cnn_time_model, cnn_freq_model, meta_df, voting='soft'):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    y_prob = [] \n",
        "\n",
        "    for _, row in meta_df.iterrows():\n",
        "        subject_id = row['subject_id']\n",
        "        label_str = row['label']\n",
        "        true_label = 1 if label_str == 'AD' else 0\n",
        "\n",
        "        segments = load_and_segment(subject_id)\n",
        "        if segments.shape[0] == 0:\n",
        "            continue\n",
        "        segments = (segments * 1e6) - np.mean(segments * 1e6, axis=2, keepdims=True)\n",
        "        top_channels = [14, 2, 0, 18, 4]\n",
        "        bilstm_input = segments[:, top_channels, :].transpose(0, 2, 1)\n",
        "        cnn_time_input = segments[..., np.newaxis]\n",
        "        spec_feats, _ = compute_spectral_features(segments)\n",
        "        cnn_freq_input = spec_feats[..., np.newaxis]\n",
        "\n",
        "        bilstm_feat = bilstm_model.predict(bilstm_input, verbose=0)\n",
        "        cnn_time_feat = cnn_time_model.predict(cnn_time_input, verbose=0)\n",
        "        cnn_freq_feat = cnn_freq_model.predict(cnn_freq_input, verbose=0)\n",
        "\n",
        "        preds = fusion_model.predict([bilstm_feat, cnn_time_feat, cnn_freq_feat], verbose=0)\n",
        "\n",
        "        if voting == 'soft':\n",
        "            avg_prob = np.mean(preds, axis=0)\n",
        "            y_pred.append(np.argmax(avg_prob))\n",
        "            y_prob.append(avg_prob[1])\n",
        "        elif voting == 'hard':\n",
        "            pred_classes = np.argmax(preds, axis=1)\n",
        "            voted_class = mode(pred_classes, keepdims=True).mode[0]\n",
        "            y_pred.append(voted_class)\n",
        "            y_prob.append(np.mean(preds[:, 1]))\n",
        "\n",
        "        y_true.append(true_label)\n",
        "\n",
        "    return np.array(y_true), np.array(y_pred), np.array(y_prob)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6ZlsY9M5Z5s"
      },
      "outputs": [],
      "source": [
        "yt_hard, yp_hard, prob_hard = patient_level_ensemble_2(fusion_model, bilstm_model, cnn_time_model, cnn_freq_model, test_meta, voting='hard')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH1nj5Uv5cEM",
        "outputId": "87189346-0846-4d13-f3fb-b85160bf0bcc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
        "\n",
        "def evaluate_predictions(y_true, y_pred, y_prob, voting_type=\"Soft\"):\n",
        "    print(f\"\\n=== {voting_type} Voting Results ===\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "evaluate_predictions(yt_hard, yp_hard, prob_hard, voting_type=\"Hard\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
